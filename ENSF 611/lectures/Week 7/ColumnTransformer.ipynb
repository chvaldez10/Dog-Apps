{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColumnTransformer\n",
    "\n",
    "Follow _Introduction to Machine Learning_  [Chapter 4](https://github.com/amueller/introduction_to_ml_with_python/blob/master/04-representing-data-feature-engineering.ipynb)\n",
    "- Section 4.3 Convenient ColumnTransformer (p.224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The file has no headers naming the columns, so we pass header=None\n",
    "# and provide the column names explicitly in \"names\"\n",
    "adult_path = os.path.join(mglearn.datasets.DATA_PATH, \"adult.data\")\n",
    "data = pd.read_csv(adult_path, header=None, index_col=False,\n",
    "    skipinitialspace=True, #remove space after comma\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education',  'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "           'income'])\n",
    "# For illustration purposes, we only select some of the columns\n",
    "data = data[['age', 'workclass', 'education', 'gender', 'hours-per-week',\n",
    "             'occupation', 'income']]\n",
    "# IPython.display allows nice output formatting within the Jupyter notebook\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaling\", StandardScaler(), ['age', 'hours-per-week']),\n",
    "     (\"onehot\", OneHotEncoder(sparse_output=False), ['workclass', 'education', 'gender', 'occupation'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# get all columns apart from income for the features\n",
    "data_features = data.drop(\"income\", axis=1)\n",
    "# split dataframe and income\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data_features, data.income, random_state=0)\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_trans = ct.transform(X_train)\n",
    "print(X_train_trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using transformed data\n",
    "\n",
    "Note that validation data `X_val` needs to be transformed with the learned transformer too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_trans, y_train)\n",
    "\n",
    "X_val_trans = ct.transform(X_val)\n",
    "print(\"Validation score: {:.2f}\".format(logreg.score(X_val_trans, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access ColumnTransformer components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.named_transformers_.onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.named_transformers_.onehot.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience function: `make_column_transformer()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), ['age', 'hours-per-week']),\n",
    "    (OneHotEncoder(sparse=False), ['workclass', 'education', 'gender', 'occupation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.named_transformers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise: Apply ColumnTransformer to heart disease data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_heart_disease():\n",
    "    '''Load and pre-process heart disease data\n",
    "    \n",
    "    if processed.hungarian.data file is not present.\n",
    "    \n",
    "    it will be downloaded from\n",
    "    https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\n",
    "    \n",
    "    return: data(DataFrame)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    \n",
    "    file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "    file_name = file_url.split('/')[-1]\n",
    "    \n",
    "    if not os.path.isfile(file_name):\n",
    "        print('Downloading from {}'.format(file_url))\n",
    "        r = requests.get(file_url)\n",
    "        with open(file_name,'wb') as output_file:\n",
    "            output_file.write(r.content)\n",
    "        \n",
    "    data = pd.read_csv(file_name, \n",
    "                   na_values='?', \n",
    "                   names=[ 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',\n",
    "                            'restecg', 'thalach', 'exang', 'oldpeak', 'slope',\n",
    "                            'ca', 'thal', 'num'])\n",
    "    \n",
    "    # drop columns with many missing data\n",
    "    data = data.drop(columns=['slope', 'ca', 'thal'])\n",
    "    \n",
    "    # fill in remaining missing data with mean() per column\n",
    "    data = data.fillna(data.mean())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_heart_disease()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which columns are numerical (quantitative), which are categorical (qualitative)?\n",
    "Consult the data description, or use `value_counts()` to guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the mean to fill in NaN, we made a mistake for the `restecg` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.restecg.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas where function replaces every value that does not satisfy the condition with the inputted value (default is NaN)\n",
    "data.restecg = data.restecg.where(data.restecg >= 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.restecg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: which columns to scale, onehot or do nothing?\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaling\", StandardScaler(), ...),\n",
    "     (\"onehot\", OneHotEncoder(sparse_output=False), ...),\n",
    "    (\"nothing\", 'passthrough', ...)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all columns apart from income for the features\n",
    "X = data.drop(columns='num')\n",
    "y = data['num']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# split dataframe and income\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                            test_size=0.1, stratify=y,random_state=31)\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_trans = ct.transform(X_train)\n",
    "print(X_train_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_trans, y_train)\n",
    "\n",
    "X_val_trans = ct.transform(X_val)\n",
    "print(\"Train score: {:.2f}\".format(logreg.score(X_train_trans, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(logreg.score(X_val_trans, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we overfitting? Let's try and reduce complexity by increasing regularization - reduce C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=0.01,max_iter=1000)\n",
    "logreg.fit(X_train_trans, y_train)\n",
    "\n",
    "X_val_trans = ct.transform(X_val)\n",
    "print(\"Train score: {:.2f}\".format(logreg.score(X_train_trans, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(logreg.score(X_val_trans, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that to the unscaled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: {:.2f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(logreg.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model is now much more flexible, it gained some non-linearity, similar to decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
