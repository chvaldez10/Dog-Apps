{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Redge Santillan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cement  1030 non-null   float64\n",
      " 1   slag    1030 non-null   float64\n",
      " 2   ash     1030 non-null   float64\n",
      " 3   water   1030 non-null   float64\n",
      " 4   splast  1030 non-null   float64\n",
      " 5   coarse  1030 non-null   float64\n",
      " 6   fine    1030 non-null   float64\n",
      " 7   age     1030 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 64.5 KB\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "X , y = load_concrete()\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# STEP 3\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "decTreeReg = DecisionTreeRegressor(random_state=0, max_depth=5)      # Decision Trees.ipynb\n",
    "rfc = RandomForestRegressor(random_state=0, max_depth=5)           # Decision Trees Example.ipynb, Ensembles.ipynb, n_estimators=100, max_features, max_depth, min_samples_leaf\n",
    "gbrt = GradientBoostingRegressor(random_state=0, max_depth=5)      # Ensembles Example, learning_rate=0.1, n_estimators=100\n",
    "\n",
    "model = [decTreeReg, rfc, gbrt]\n",
    "results_dict_1 = {\n",
    "    \"Model\": [\"DecisionTreeRegressor\", \"RandomForestRegressor\", \"GradientBoostingRegressor\"],\n",
    "    \"X size\": [],\n",
    "    \"y size\": [],\n",
    "    \"Neg MSE (Training)\" : [],\n",
    "    \"Neg MSE (Testing)\" : [],\n",
    "    \"R2 Error (Training)\" : [],\n",
    "    \"R2 Error (Testing)\" : []\n",
    "}\n",
    "\n",
    "for n in range(3):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                     random_state=0)\n",
    "    (model[n]).fit(X_train, y_train)                                        # model fit line\n",
    "    results_dict_1[\"X size\"].append(X.shape)\n",
    "    results_dict_1[\"y size\"].append(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d12314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_result = [0] * 3\n",
    "\n",
    "for n in range(0,3):\n",
    "    cv_result[n] = cross_validate(model[n], X_train, y_train, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    neg_mse_train = cv_result[n]['train_score'].mean() * (-1)\n",
    "    neg_mse_test = cv_result[n]['test_score'].mean() * (-1)\n",
    "\n",
    "    results_dict_1[\"Neg MSE (Training)\"].append(neg_mse_train)\n",
    "    results_dict_1[\"Neg MSE (Testing)\"].append(neg_mse_test)\n",
    "\n",
    "# print(cv_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83539f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "cv_result = [0] * 3\n",
    "\n",
    "for n in range(0,3):\n",
    "    cv_result[n] = cross_validate(model[n], X_train, y_train.values.ravel(), scoring='r2', return_train_score=True)\n",
    "    r2_error_train = cv_result[n]['train_score'].mean()\n",
    "    r2_error_test = cv_result[n]['test_score'].mean()\n",
    "    \n",
    "    results_dict_1[\"R2 Error (Training)\"].append(r2_error_train)\n",
    "    results_dict_1[\"R2 Error (Testing)\"].append(r2_error_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de8a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>X size</th>\n",
       "      <th>y size</th>\n",
       "      <th>Neg MSE (Training)</th>\n",
       "      <th>Neg MSE (Testing)</th>\n",
       "      <th>R2 Error (Training)</th>\n",
       "      <th>R2 Error (Testing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>(1030, 8)</td>\n",
       "      <td>(1030,)</td>\n",
       "      <td>47.279761</td>\n",
       "      <td>73.447331</td>\n",
       "      <td>0.834465</td>\n",
       "      <td>0.738697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>(1030, 8)</td>\n",
       "      <td>(1030,)</td>\n",
       "      <td>29.576135</td>\n",
       "      <td>45.052441</td>\n",
       "      <td>0.896561</td>\n",
       "      <td>0.840951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>(1030, 8)</td>\n",
       "      <td>(1030,)</td>\n",
       "      <td>3.379440</td>\n",
       "      <td>22.819636</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.919348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model     X size   y size  Neg MSE (Training)  \\\n",
       "0      DecisionTreeRegressor  (1030, 8)  (1030,)           47.279761   \n",
       "1      RandomForestRegressor  (1030, 8)  (1030,)           29.576135   \n",
       "2  GradientBoostingRegressor  (1030, 8)  (1030,)            3.379440   \n",
       "\n",
       "   Neg MSE (Testing)  R2 Error (Training)  R2 Error (Testing)  \n",
       "0          73.447331             0.834465            0.738697  \n",
       "1          45.052441             0.896561            0.840951  \n",
       "2          22.819636             0.988171            0.919348  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5 \n",
    "results_df_1 = pd.DataFrame(results_dict_1)\n",
    "results_df_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d878cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>X size</th>\n",
       "      <th>y size</th>\n",
       "      <th>Neg MSE (Training)</th>\n",
       "      <th>Neg MSE (Testing)</th>\n",
       "      <th>R2 Error (Training)</th>\n",
       "      <th>R2 Error (Testing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>(1030, 8)</td>\n",
       "      <td>(1030,)</td>\n",
       "      <td>47.279761</td>\n",
       "      <td>73.447331</td>\n",
       "      <td>0.834465</td>\n",
       "      <td>0.738697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>(1030, 8)</td>\n",
       "      <td>(1030,)</td>\n",
       "      <td>29.576135</td>\n",
       "      <td>45.052441</td>\n",
       "      <td>0.896561</td>\n",
       "      <td>0.840951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>(1030, 8)</td>\n",
       "      <td>(1030,)</td>\n",
       "      <td>3.379440</td>\n",
       "      <td>22.819636</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.919348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assignment2 - LinearRegression</td>\n",
       "      <td>(1030, 8)</td>\n",
       "      <td>(1030,)</td>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904136</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model     X size   y size  Neg MSE (Training)  \\\n",
       "0           DecisionTreeRegressor  (1030, 8)  (1030,)           47.279761   \n",
       "1           RandomForestRegressor  (1030, 8)  (1030,)           29.576135   \n",
       "2       GradientBoostingRegressor  (1030, 8)  (1030,)            3.379440   \n",
       "3  Assignment2 - LinearRegression  (1030, 8)  (1030,)          111.358439   \n",
       "\n",
       "   Neg MSE (Testing)  R2 Error (Training)  R2 Error (Testing)  \n",
       "0          73.447331             0.834465            0.738697  \n",
       "1          45.052441             0.896561            0.840951  \n",
       "2          22.819636             0.988171            0.919348  \n",
       "3          95.904136             0.610823            0.623414  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding assignment 2 values to compare values\n",
    "new_row = [\"Assignment2 - LinearRegression\", \"(1030, 8)\",\"(1030,)\",111.358439, 95.904136, 0.610823, 0.623414]\n",
    "results_df_1.loc[len(results_df_1)] = new_row\n",
    "results_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "##### ANSWERS: #####\n",
    "1. The 3 models used in Part 1 were able to produce better results than the LinearRegression model used in Assignment 2 (as shown above).\n",
    "1. `GradientBoostingRegressor()` performed better than the rest, as showcased by the model's NegMSE and R2 Error scores. The MSE values were close to the ideal value of 0, meaning that the model was very close to the true values. The R2 Errors were the closest to 1, meaning that it had the best \"goodness of fit\".\n",
    "1. One suggestion would be to increase the max_depth of the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc39da",
   "metadata": {},
   "source": [
    "#### ANSWERS: ####\n",
    "1. Example jupyter notebooks, googling, peer discussion.\n",
    "1. Did all the data imports first. Then the code and number-crunching. Lastly, the questions.\n",
    "1. Generative AI prompts used:\n",
    "    - *\"Why do a cross-validation score with the training set if we can just get the testing accuracy score with the testing set?\"*\n",
    "1. I had some technical issues with some functions giving me warnings about taking in a column vector. The error message was something like this:\n",
    "    >```DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().```\n",
    "    >```y = column_or_1d(y, warn=True)```\n",
    "    \n",
    "    For some of them, I was able to make the message go away (I used `y_train.values.ravel()` in my `cross_validate()` function calls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b39836",
   "metadata": {},
   "source": [
    "#### Importing the data ####\n",
    "To execute the data import, install `ucimlrep` via a `pip install ucimlrepo` command. If on Colab, run cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c694cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 109, 'name': 'Wine', 'repository_url': 'https://archive.ics.uci.edu/dataset/109/wine', 'data_url': 'https://archive.ics.uci.edu/static/public/109/data.csv', 'abstract': 'Using chemical analysis to determine the origin of wines', 'area': 'Physical Science', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 178, 'num_features': 13, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1992, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C5PC7J', 'creators': ['Stefan Aeberhard', 'M. Forina'], 'intro_paper': {'title': 'Comparative analysis of statistical pattern recognition methods in high dimensional settings', 'authors': 'S. Aeberhard, D. Coomans, O. Vel', 'published_in': 'Pattern Recognition', 'year': 1994, 'url': 'https://www.semanticscholar.org/paper/83dc3e4030d7b9fbdbb4bde03ce12ab70ca10528', 'doi': '10.1016/0031-3203(94)90145-7'}, 'additional_info': {'summary': 'These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. \\r\\n\\r\\nI think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.)  I lost it, and b.), I would not know which 13 variables are included in the set.\\r\\n\\r\\nThe attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it )\\r\\n1) Alcohol\\r\\n2) Malic acid\\r\\n3) Ash\\r\\n4) Alcalinity of ash  \\r\\n5) Magnesium\\r\\n6) Total phenols\\r\\n7) Flavanoids\\r\\n8) Nonflavanoid phenols\\r\\n9) Proanthocyanins\\r\\n10)Color intensity\\r\\n11)Hue\\r\\n12)OD280/OD315 of diluted wines\\r\\n13)Proline \\r\\n\\r\\nIn a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging.           ', 'purpose': 'test', 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'All attributes are continuous\\r\\n\\t\\r\\nNo statistics available, but suggest to standardise variables for certain uses (e.g. for us with classifiers which are NOT scale invariant)\\r\\n\\r\\nNOTE: 1st attribute is class identifier (1-3)', 'citation': None}}\n",
      "                            name     role         type demographic  \\\n",
      "0                          class   Target  Categorical        None   \n",
      "1                        Alcohol  Feature   Continuous        None   \n",
      "2                      Malicacid  Feature   Continuous        None   \n",
      "3                            Ash  Feature   Continuous        None   \n",
      "4              Alcalinity_of_ash  Feature   Continuous        None   \n",
      "5                      Magnesium  Feature      Integer        None   \n",
      "6                  Total_phenols  Feature   Continuous        None   \n",
      "7                     Flavanoids  Feature   Continuous        None   \n",
      "8           Nonflavanoid_phenols  Feature   Continuous        None   \n",
      "9                Proanthocyanins  Feature   Continuous        None   \n",
      "10               Color_intensity  Feature   Continuous        None   \n",
      "11                           Hue  Feature   Continuous        None   \n",
      "12  0D280_0D315_of_diluted_wines  Feature   Continuous        None   \n",
      "13                       Proline  Feature      Integer        None   \n",
      "\n",
      "   description units missing_values  \n",
      "0         None  None             no  \n",
      "1         None  None             no  \n",
      "2         None  None             no  \n",
      "3         None  None             no  \n",
      "4         None  None             no  \n",
      "5         None  None             no  \n",
      "6         None  None             no  \n",
      "7         None  None             no  \n",
      "8         None  None             no  \n",
      "9         None  None             no  \n",
      "10        None  None             no  \n",
      "11        None  None             no  \n",
      "12        None  None             no  \n",
      "13        None  None             no  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "\n",
    "# From the website:\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo         # do a pip install ucimlrepo\n",
    "# fetch dataset \n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine.data.features \n",
    "y = wine.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(wine.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(wine.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0284b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'ucimlrepo.dotdict.dotdict'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(type(X))\n",
    "print(type(wine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of X:\n",
      "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
      "0    14.23       1.71  2.43               15.6        127           2.80   \n",
      "1    13.20       1.78  2.14               11.2        100           2.65   \n",
      "2    13.16       2.36  2.67               18.6        101           2.80   \n",
      "3    14.37       1.95  2.50               16.8        113           3.85   \n",
      "4    13.24       2.59  2.87               21.0        118           2.80   \n",
      "\n",
      "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   0D280_0D315_of_diluted_wines  Proline  \n",
      "0                          3.92     1065  \n",
      "1                          3.40     1050  \n",
      "2                          3.17     1185  \n",
      "3                          3.45     1480  \n",
      "4                          2.93      735  \n",
      "First 5 rows of y:\n",
      "   class\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(\"First 5 rows of X:\")\n",
    "print(X.head(5))\n",
    "print(\"First 5 rows of y:\")\n",
    "print(y.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol                         0\n",
      "Malicacid                       0\n",
      "Ash                             0\n",
      "Alcalinity_of_ash               0\n",
      "Magnesium                       0\n",
      "Total_phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid_phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color_intensity                 0\n",
      "Hue                             0\n",
      "0D280_0D315_of_diluted_wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n",
      "\n",
      "Alcohol                         0\n",
      "Malicacid                       0\n",
      "Ash                             0\n",
      "Alcalinity_of_ash               0\n",
      "Magnesium                       0\n",
      "Total_phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid_phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color_intensity                 0\n",
      "Hue                             0\n",
      "0D280_0D315_of_diluted_wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X_nulls = X.isnull().sum().sort_values(ascending=False)\n",
    "y_nulls = X.isnull().sum().sort_values(ascending=False)\n",
    "print(X_nulls)\n",
    "print()\n",
    "print(y_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "2        71\n",
      "1        59\n",
      "3        48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# STEP 3: \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "decTreeCla = DecisionTreeClassifier(random_state=0, max_depth=3)\n",
    "svc = SVC(random_state=0)\n",
    "\n",
    "model = [decTreeCla, svc]\n",
    "results_dict_2 = {\n",
    "    \"Model\": [\"DecisionTreeClassifier\", \"SVC\"],\n",
    "    \"X size\": [],\n",
    "    \"y size\": [],\n",
    "    \"Accuracy (Training)\" : [],\n",
    "    \"Accuracy (Testing)\" : []\n",
    "}\n",
    "\n",
    "for n in range(2):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                     random_state=0)\n",
    "    (model[n]).fit(X_train, y_train)\n",
    "\n",
    "    results_dict_2[\"X size\"].append(X.shape)\n",
    "    results_dict_2[\"y size\"].append(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea800a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8940170940170941\n",
      "0.6766381766381766\n"
     ]
    }
   ],
   "source": [
    "# STEP 4:\n",
    "\n",
    "cv_result = [0] * 2\n",
    "\n",
    "for n in range(0,2):\n",
    "    cv_result[n] = cross_validate(model[n], X_train, y_train.values.ravel(), scoring='accuracy', return_train_score=True)\n",
    "    acc_score_test = cv_result[n]['test_score'].mean()\n",
    "    acc_score_train = cv_result[n]['train_score'].mean()\n",
    "    # print(neg_mse_test)\n",
    "    print(acc_score_test)\n",
    "    results_dict_2[\"Accuracy (Testing)\"].append(acc_score_test)\n",
    "    results_dict_2[\"Accuracy (Training)\"].append(acc_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2808b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>X size</th>\n",
       "      <th>y size</th>\n",
       "      <th>Accuracy (Training)</th>\n",
       "      <th>Accuracy (Testing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>(178, 13)</td>\n",
       "      <td>(178, 1)</td>\n",
       "      <td>0.994357</td>\n",
       "      <td>0.894017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>(178, 13)</td>\n",
       "      <td>(178, 1)</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>0.676638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model     X size    y size  Accuracy (Training)  \\\n",
       "0  DecisionTreeClassifier  (178, 13)  (178, 1)             0.994357   \n",
       "1                     SVC  (178, 13)  (178, 1)             0.680427   \n",
       "\n",
       "   Accuracy (Testing)  \n",
       "0            0.894017  \n",
       "1            0.676638  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5:\n",
    "results_df_2 = pd.DataFrame(results_dict_2)\n",
    "results_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model\n",
    "# DTC was better\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, decTreeCla.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  2  0]\n",
      " [ 0 20  1]\n",
      " [ 0  0  8]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAHkCAYAAADvrlz5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgbElEQVR4nO3df1RUdf7H8degopLmz0ozrTDQskxMSTc7llpZqyWGq2mS1m66Zm34M63N0vJXu2L0Q7+7aZaUuvkrUSmzpbbMytLV1jCEXEBorRASBAXkfv/w23xj1XRo8L4Hno9z9mzzuZc7bzh1nsy9w1yP4ziOAACAq4LcHgAAABBkAABMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAA2q7PYA/FY673e0REGA6L81xewQEoK9/+MbtERBgykqyT7sPr5ABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyNWQp3FznfP066rV9spT7lPn+v5qMG+dPE3OP4uTIRAMHh6lde8t045//0PvblurqU+N0zkNznF7LBh2y8036OOtG3UoP03pez/R5Elj3R4pIBHkasbT5DzVHzVdnvoNTr1P85YK/nXMWZwKgeK3Y2M0be5kvb/5Qz0QM0F/fX6pbr/zVr2wZK7bo8Go7t26aM3ql7VnT5oG/ea3eu31VZoxfbKmPPKQ26MFnNpuDwA/8XhUu0sv1b195Gn2C1K9ux6Wc/iQPMHnnZ3ZEBA8Ho9G/WGEVry6Wn9+6gVJ0kf/+FT5efmKXzRHV159uf61M8XlKWHNHx+L1c6duzVi5PEAv73pPdWpU1uTJj6guPl/0ZEjR1yeMHDwCrmaCGp5iepG/16l2/6uI6/HnXK/OjcOkKdhY5X+fdVZnA6BoEHDc7RuZZISV71dYf3f6ZmSpDaXXuTGWDAsODhYPXt215q1SRXWV63aoIYNG+j6HpEuTRaYXA9yYWGhDhw4oMLCQrdHCWjl+d+paOYolaxbLJUcPek+QRe0VvAtd+nIing5JfzWiooKDhVqxpRntP3TnRXWb/71jZKk1JR0N8aCYaGhbVS3bl2l7v26wnpa+r8lSWFhoS5MFbhcOWVdXl6uJUuWKCEhQd988413vUWLFoqOjtaYMWPk8XjcGC1wFRXK0c/8UhMUpLpDH1bpx++oPH23gppecPZmQ8CK6NpRv3vwHr2zIVlpX319+i9AjdK4USNJx3+Z+6mCguOPzz234VmfKZC5EuTZs2dr69atmjBhgi677DLVr19fxcXFSktL04IFC1RUVKSJEye6MVq1VafPb+Sp30AlG15xexQEiC7dOmlhQpwy/71fUx+e4fY4MCgo6PgLJ8dxTrq9vLz8bI4T8FwJcmJiot544w1ddFHFa1Lh4eG66qqrNGTIEILsR0GtQhXcZ5CO/PVJqaxUCgqSPP93teLHf3b4Dwf/79cDbtbs56ZpX1qG7h38oH7IP+T2SDAo/4fj/140PLfiX3U0bHj88Q8/FJz1mQKZK0EuKyvT+eef/O9fmzZtqmPHjp3liaq32ldeK0/tOqr/+6dO2HbOo3/RsbQvVPzioy5MBovue2C4Jj7+oLZt3aHfDx+nwoLDbo8Eo9LTM1RWVqbL2l5SYf3HxykpqWd/qADmSpAjIyP12GOPadKkSWrevLl3/eDBg3r66ad17bXXujFWtVW69W2V7d5WYa12h64KvuUuFb80Q+Xf5bg0GawZHDNQk5/4gzau3aSJYx5XaWmZ2yPBsKNHj+qDDz5R1IDb9Od5C73rd975a+Xl5evTbf90b7gA5EqQZ8yYoT/84Q+6/vrr1ahRI4WEhKi4uFj5+fm65pprFB8f78ZY1ZZz6KCcQwcrrJW3bHP8/7/JkJP3rRtjwZjm5zfT1BnjtD8zR0tfWqErOravsD3z3/uVl5vvznAwa+asZ/X2W8u1fNn/aMmS5erevYvGj/u9pkx9mr9B9pErQW7atKmWLl2qzMxM7d27V4cPH1ZISIjCwsJ08cUXuzESUOP17HOd6ofU00VtLtSy9YtO2D75wSe0Zvl6FyaDZcnvbdGgwb/TtMfHa9XKRcrO/o8mP/KU4ub/j9ujBRyPc6q3xwWgwnG3uz0CAkznpZyuh+++/uGb0+8E/ERZSfZp93H9g0EAAABBBgDABIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwwOM4juP2EP5SO7iV2yMgwBTnfOD2CAhALUP7uj0CAsz3h1JPuw+vkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAZUKsjffvutnn/+eY0bN065ublKSkpSenq6v2cDAKDG8DnIGRkZ6t+/v9asWaNNmzapqKhISUlJio6O1vbt26tiRgAAqj2fgzx79mz16dNHmzdvVp06dSRJcXFx6tOnj+bNm+f3AQEAqAl8DvKOHTs0cuRIeTwe71qtWrU0evRopaSk+HU4AABqCp+DfOzYMZWXl5+wXlhYqFq1avllKAAAahqfg9yjRw8tWLBAx44d867l5eXpmWeeUbdu3fw6HAAANYXHcRzHly84cOCAYmJilJ+fr4KCAoWGhio7O1uNGzdWQkKCWrVqVVWznlbtYPeeG4GpOOcDt0dAAGoZ2tftERBgvj+Uetp9fA6yJBUXF2v9+vVKSUlReXm5wsLCdMcdd6hBgwaVGtRfCDJ8RZBRGQQZvjqTINeuzIHr16+vQYMGVeZLAQDASfgc5JiYmJ/d/uqrr1Z6GAAAaiqfg/zf14hLS0uVmZmp1NRUjRgxwl9zAQBQo/gc5FmzZp10PT4+Xrm5ub94IAAAaiK/3VwiKipKSUlJ/jocAAA1it+CnJaWpkq8YRsAAKgSp6ynTJlywlpBQYG2bNmivn35UwAAACrD5yDv37//hLXg4GDdd999GjlypF+GAgCgpvE5yEuXLq2KOQAAqNHOKMg5OTlnfMALL7yw0sMAAFBTnVGQe/XqVeF2iyfjOI48Hg+3YAQAoBLOKMh8+hYAAFXrjIIcGRlZ1XMAAFCj+fymrpKSEq1YsUJfffVVhXsil5SU6IsvvtCmTZv8OiAAADWBz0GeOXOmVq9erQ4dOmjnzp2KiIhQRkaGcnNz+SxrAAAqyedP6tq8ebNmz56tZcuW6aKLLtKMGTOUnJys3r17q7S0tCpmBACg2vM5yPn5+erUqZMkKTw8XF9++aXq1KmjUaNGKTk52d/zAQBQI/gc5ObNm3vv6tSmTRulpqZKkpo0aaLvv//ev9MBAFBD+Bzknj17atq0afrqq6/UuXNnJSYm6osvvtBrr72mFi1aVMWMAABUez4HecKECWrRooU+++wz9e7dW2FhYRo0aJCWLl2qhx56qCpmBACg2vM4frhn4pdffqnmzZvr/PPP98dMlVY7uJWrz4/AU5zzgdsjIAC1DOXOdvDN94dST7uPz6+Qe/Xqpfj4eGVlZXnXrrjiCtdjDABAIPM5yIMGDdLbb7+tm2++WUOHDtXKlStVWFhYFbMBAFBjVPqU9b/+9S+9+eabSkpKUmFhoW666SZFRUXpV7/6lb9nPGOcsoavOGWNyuCUNXx1Jqesf/E15PLycr3++uuKi4tTUVGRq3d7IsjwFUFGZRBk+OpMguzzR2f+KCcnR+vXr1diYqLS09MVGRmpgQMHnvHXb9u27bT7dO3atbLjAQAQUHwO8vLly5WYmKgdO3aoVatWGjBggKKionThhRf6dJxHH31UWVlZOtULdO6tDACoSXw+ZR0REaG+fftq4MCBv+gV7MGDBzVkyBDFxsbq1ltvrfRxfopT1vAVp6xRGZyyhq+q5BpyUVGRQkJCKj3UT33++eeaOHGiNm/erKAgn9/wfQKCDF8RZFQGQYavquTvkP0VY0m65ppr9NBDDykvL89vxwQAIBBV+k1d/jJgwAC3RwAAwHW//DwxAAD4xQgyAAAGVCrI3377rZ5//nmNGzdOubm5SkpKUnp6ur9nAwCgxvA5yBkZGerfv7/WrFmjTZs2qaioSElJSYqOjtb27durYkYAAKo9n4M8e/Zs9enTR5s3b1adOnUkSXFxcerTp4/mzZvn9wEBAKgJfA7yjh07NHLkSHk8Hu9arVq1NHr0aD5ZCwCASvI5yMeOHVN5efkJ64WFhapVq5ZfhgIAoKbxOcg9evTQggULdOzYMe9aXl6ennnmGXXr1s2vwwEAUFP4/NGZBw4cUExMjPLz81VQUKDQ0FBlZ2ercePGSkhIUKtW7n18JR+dCV/x0ZmoDD46E76qsvshFxcXa/369UpJSVF5ebnCwsJ0xx13qEGDBpUa1F8IMnxFkFEZBBm+qrL7IdevX1+DBg2qzJcCAICT8DnIMTExP7v91VdfrfQwAADUVD4H+b+vEZeWliozM1OpqakaMWKEv+YCAKBG8TnIs2bNOul6fHy8cnNzf/FAAADURH67uURUVJSSkpL8dTgAAGoUvwU5LS1NlXjDNgAAUCVOWU+ZMuWEtYKCAm3ZskV9+/KnAAAAVIbPQd6/f/8Ja8HBwbrvvvs0cuRIvwwFAEBN43OQH3zwQXXq1EnBwcFVMQ8AADWSz9eQH3roIe3du7cqZgEAoMbyOcjNmjVTQUFBVcwCAECN5fMp6x49emjUqFHq2bOnLr74YtWtW7fC9rFjx/ptOAAAagqfby7Rq1evUx/M49G77777i4eqLG4uAV9xcwlUBjeXgK+q5OYSf//730+5rby83NfDAQAAVeIacu/evZWfn3/C+oEDB9S9e3d/zAQAQI1zRq+QN27cqA8+OH5qLzs7W9OnTz/h2nF2drY8Ho//JwQAoAY4oyBHRERo+fLl3o/GzMnJUZ06dbzbPR6PQkJCNGfOnKqZEgCAas7nN3UNHz5cL7zwgs4999yqmqnSeFMXfMWbulAZvKkLvqqSN3UtXbq0UsMAAIBT89vdngAAQOURZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhQ2+0BADfVv/B6t0dAAFp83o1uj4BqiFfIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwABXgpyXl6fRo0era9euGjFihNLS0ips79y5sxtjAQDgGleCPHv2bDmOozlz5uj888/XsGHDKkTZcRw3xgIAwDW13XjSLVu2aMOGDWrUqJF69eqluLg4jRo1SqtXr1ajRo3k8XjcGAsAANe48gq5tLRUDRo08D6OjY3VFVdcoXHjxkniFTIAoOZxJcgdOnTQggULKoR31qxZys7O1tSpU90YCQAAV7kS5EmTJmnFihUaNWqUd61Bgwb6y1/+oq1bt+rIkSNujAUAgGtcuYbcvn17bd68WTk5ORXW27RpozfffFOrV692YywAAFzjcarRBdvawa3cHgFADbD4vBvdHgEBJiY74bT78MEgAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAzwOI7juD0EAAA1Ha+QAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIFdzubm5GjNmjLp06aJrr71WTz/9tMrKytweCwHg4MGDuummm/TJJ5+4PQqM27Nnj0aOHKnIyEhdd911mjRpkg4ePOj2WAGHIFdzDz/8sEJCQvTBBx9o5cqV2rp1q5YsWeL2WDDu888/1+DBg5WZmen2KDDuyJEj+u1vf6uIiAh9+OGHWr9+vfLz8zV16lS3Rws4BLkay8jI0KeffqqJEyeqfv36at26tcaMGaPXXnvN7dFg2Jo1azRhwgTFxsa6PQoCQE5Ojtq3b68HHnhAwcHBatKkiQYPHqxt27a5PVrAIcjV2N69e9W4cWNdcMEF3rW2bdsqJydHhw4dcnEyWNajRw+98847uu2229weBQEgNDRUL730kmrVquVde/vtt9WhQwcXpwpMtd0eAFXn8OHDql+/foW1Hx8XFRXp3HPPdWMsGHfeeee5PQIClOM4mj9/vpKTk5WQkOD2OAGHIFdjISEhKi4urrD24+NzzjnHjZEAVFOFhYWaMmWKdu/erYSEBLVr187tkQIOp6yrsbCwMOXn5+v777/3rqWnp6tFixZq2LChi5MBqE4yMzN15513qrCwUCtXriTGlUSQq7FLLrlE11xzjWbOnKnCwkJlZWXpxRdfVHR0tNujAagmfvjhB91zzz3q3LmzFi1apKZNm7o9UsDilHU1Fx8fr+nTp6t3794KCgrSgAEDNGbMGLfHAlBNrF69Wjk5OUpKStJbb71VYduOHTtcmioweRzHcdweAgCAmo5T1gAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIQIDq1auXnnvuOUnHPy3Jl88PTk5OVlpa2i96/uHDh+uRRx75Rcf4OT/9/oCagCAD1cBtt92mDz/88Iz2zc7O1ujRo5Wbm1vFUwHwBZ9lDVQD9erVU7169c5oXz4tF7CJV8iAH7Vr107Lli3TXXfdpY4dO6p///569913vdufe+45DRkyROPGjVPnzp315JNPSpK2b9+uYcOGqWPHjrrhhhv05JNPqrCw0Pt1BQUFmjx5srp06aLu3btryZIlFZ73v09ZFxUV6amnnlKPHj0UERGhYcOGadeuXdq/f7969+4tSYqJifGeEk5PT9fvfvc7RUREqEePHho/fry+++477/FKSko0c+ZMde/eXV26dNGf//xnlZeXn/Ln8Mgjj2jQoEEV1v7zn//o8ssv19atWyVJq1at0oABA9SxY0d16tRJw4cP1+7du096vJOdkv/kk0/Url077d+/X9LxXzT++te/qnfv3rr66qt1xx13aN26daecEbCGIAN+NnfuXPXr109r165Vz549NXbsWG3fvt27fceOHWrWrJnefPNN3XPPPdqzZ49GjBih6667TuvWrdOf/vQn7d69W/fee6/31ezDDz+sXbt2aeHChVq8eLGSk5OVnZ19yhliY2OVnJysmTNnau3atbr00kt13333qV69enrjjTckHf/l4N5779WBAwc0dOhQtW7dWitXrtTChQtVWFioIUOGqKioSJL01FNPaePGjZo9e7aWLVumnJwcffbZZ6d8/qioKO3atUsZGRnetXXr1umCCy7Qtddeq3feeUfTpk3TiBEjlJSUpFdeeUVHjhzRo48+Wumfe1xcnF5//XU99thjSkxMVExMjJ544gm99tprlT4mcFY5APwmPDzcmTFjRoW13/zmN05sbKzjOI4THx/vhIeHO4cOHfJunzBhgnP//fdX+JrMzEwnPDzc+fjjj5309HQnPDzc+eijj7zbv/vuO+fKK6904uPjHcdxnFWrVjnh4eGO4zjO119/7YSHhzv/+Mc/vPsfPXrUmTlzppOenu5kZWV5j+04jhMXF+f069evwvMXFRU5HTt2dFatWuUUFBQ4HTp0cP72t795tx85csS57rrrnMmTJ5/051BeXu707t3bee6557xr/fr1c+bNm+c4juN8+umnzpo1ayp8zYoVK5z27dt7H994440n/f5+9PHHHzvh4eFOVlaWc/jwYeeqq65ykpKSKuzz7LPPOjfeeONJZwSs4Roy4GeRkZEVHl999dX66KOPvI+bNWumhg0beh9/+eWXysjIUERExAnHSk9PV15eniTpqquu8q43b95crVu3Punzf/XVV5KkTp06edeCg4M1ZcoUSfKe4v3p86enp5/w/EePHlV6err27dun0tLSCs9ft25dXX755Sd9fknyeDwaMGCAEhMTNXbsWKWkpCg1NVXx8fGSpK5du6pp06Z68cUXlZGRoX379iklJeVnT4P/nLS0NB09elSTJ0/2fp+SVFZWppKSEh05cuSMr7EDbiHIgJ/Vrl3xP6vy8nIFBf3/1aH/DkN5ebn69++v0aNHn3Cspk2basuWLd79fu55/nvd4/Gc0bzl5eXq1q2bpk2bdsK2hg0bnvLU+Kme/0dRUVF6/vnntWvXLiUlJSkiIkKXXnqpJGnDhg2aNGmS+vXrp44dOyo6OlqpqamaPn36zx7TcRzv91VWVlZhXZLmz5+v0NDQE74uODj4Z48LWMA1ZMDPvvjiiwqP//nPf6pDhw6n3D8sLEx79+7VxRdf7P3fsWPHNGvWLH3zzTe64oorJKnCdehDhw4pMzPzpMdr27btCXOUlZXphhtu0IYNG04IdVhYmNLT09WyZUvv8zdq1EgzZ85Uamqq2rZtq7p16+rzzz+vcLw9e/b87M+hVatWioyM1FtvvaWNGzcqKirKu23hwoWKjo7WnDlzNGzYMHXt2lVZWVmSTv4u8Dp16kg6/ua2H/30+nRoaKhq166tnJycCj/H999/X4sWLarwCxFgFf+WAn72yiuvKDExUfv27dOcOXO0Z88e3XPPPafc/95771VKSooef/xxpaWlaefOnZowYYL27dunSy65RG3atFHfvn01ffp0ffTRR0pNTdWkSZNUUlJy0uNdeumluvnmm/Xkk09q69at2rdvnx5//HGVlJSoe/fuCgkJkSSlpqaqoKBAQ4cOVUFBgcaNG6eUlBTt2bNH48eP165duxQWFqaQkBDdfffdio+P16ZNm5Senq5p06bpwIEDp/1ZDBw4UMuXL1deXp5uu+0273rLli21fft27d69W5mZmVqyZIkSEhIk6aTfV6dOnRQUFKT58+crKytL7733nhYvXuzd3rBhQw0ZMkTz58/X2rVrlZWVpTVr1uiZZ55R8+bNTzsnYAFBBvxs8ODBevnll3X77bfrs88+06JFi9S+fftT7t+pUye99NJLSk1N1cCBA3X//ferdevWevnll72nWufMmaMbbrhBsbGxGjZsmC677DJdeeWVpzzmrFmzFBkZqdjYWA0cOFA5OTlavHixmjZtqiZNmujOO+/U3Llz9eyzz6p169ZKSEhQcXGxhg4dqrvvvlsej0evvPKKmjVrJkkaP368hg4dqunTpys6OlqO46hXr16n/VnccsstkqQ+ffpUuG7+xz/+Uc2bN9fdd9+tQYMGKTk5WXPnzpUk7dy584TjtG7dWtOnT9f777+vW2+9VQsWLNDUqVMr7DNlyhSNGDFC8fHxuvXWW/XCCy9o7NixevDBB087J2CBxznZ+SEAldKuXTvNmjVLAwcOdHsUAAGGV8gAABhAkAEAMIBT1gAAGMArZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABvwvSogSgn4KdowAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n",
    "\n",
    "\n",
    "# For some reason, the last 6 numbers were not printing on VS code. Please see my 'mat' variable printout.\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.91      0.95      0.93        21\n",
      "           3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, decTreeCla.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a82e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "Accuracy (Training) = 0.37594780461999655\n",
      "Accuracy (Testing) = 0.37606837606837606\n",
      "C = 0.01\n",
      "Accuracy (Training) = 0.37594780461999655\n",
      "Accuracy (Testing) = 0.37606837606837606\n",
      "C = 0.1\n",
      "Accuracy (Training) = 0.9774642920119909\n",
      "Accuracy (Testing) = 0.9472934472934472\n",
      "C = 1\n",
      "Accuracy (Training) = 0.9943572562158348\n",
      "Accuracy (Testing) = 0.9774928774928775\n",
      "C = 10\n",
      "Accuracy (Training) = 1.0\n",
      "Accuracy (Testing) = 0.9549857549857549\n",
      "C = 100\n",
      "Accuracy (Training) = 1.0\n",
      "Accuracy (Testing) = 0.9549857549857549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Looking at the effect of varying C hyperparameter on a scaled dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "cv_result = [0] * 6\n",
    "counter = 0\n",
    "\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svc = SVC(C=c).fit(X_train_scaled, y_train)\n",
    "    cv_result[counter] = cross_validate(svc, X_train_scaled, y_train.values.ravel(), scoring='accuracy', return_train_score=True)\n",
    "    acc_score_train = cv_result[counter]['train_score'].mean()\n",
    "    acc_score_test = cv_result[counter]['test_score'].mean()\n",
    "    # print(neg_mse_test)\n",
    "    print(f\"C = {c}\")\n",
    "    print(f\"Accuracy (Training) = {acc_score_train}\")\n",
    "    print(f\"Accuracy (Testing) = {acc_score_test}\")\n",
    "    results_dict_2[\"Accuracy (Testing)\"].append(acc_score_test)\n",
    "    results_dict_2[\"Accuracy (Training)\"].append(acc_score_train)\n",
    "    # print(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "    # print(\"Accuracy on validation set: {:.2f}\".format(svc.score(X_val_scaled, y_val)))\n",
    "    counter += counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "#### ANSWERS: ####\n",
    "1. The training and validation accuracy were vastly different. `DecisionTreeClassifier()` had training and validation accuracy scores of `0.994357`, and `0.894017`, respectively. This meant that the model was very close to perfectly fitting the training data, and did an excellent job at predicting with the testing data. On the other hand `SVC()` only achieved `0.680427` and `0.676638` in the same respective scores.\n",
    "\n",
    "    Model                   | Accuracy (Training)| Accuracy (Testing)\n",
    "    ------------------------|--------------------|-------------------\n",
    "    DecisionTreeClassifier  | **0.994357**\t     |**0.894017** \n",
    "    SVC                     | 0.680427           |0.676638\n",
    "\n",
    "1. Support vector machines model did not work as well as the tree-based model.\n",
    "    - First reason as to why  is that we did not change the values of `C` and `gamma` in the `SVC()` model. These two hyperparameters control the complexity of the model. Another reason could be that we did not scale the training data prior to fitting with `SVC()`.\n",
    "1. A total of 3 values were incorrectly predicted in Step 5.2\n",
    "1. Since improving recall will reduce precision, and vice versa. And with the numbers being very close, improving either one will result in decreasing the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "#### ANSWERS: ####\n",
    "1. Example jupyter notebooks, googling, peer discussion.\n",
    "1. Did all the data imports first. Then the code and number-crunching. Lastly, the questions.\n",
    "1. Generative AI prompts used:\n",
    "    - *\"When evaluating an ML model's performance using MSE and R2 scores, what are the ideal values to strive for. Explain why each ideal situation is better.\"* and *\"How are each of them related to bias and variance\"*\n",
    "1. For some reason, some of the numbers in the `sns.heatmap()` visualization doesn't show all the numbers in the confusion matrix. I printed the `mat` variable to confirm that I did indeed get resuts for those missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "#### ANSWER: ####\n",
    "\n",
    "Some models just work better right from the get-go, without even modifying hyperparameters (shown in the above table). The way that these two models predict the target variables are different, and hence your usage of either one really depends on your data, and what results you get (an iterative tweaking process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "#### ANSWER: ####\n",
    "- I liked seeing the visual of the confusion matrix - very effective at demonstrating the classification results from the training.\n",
    "- I was confused about which dataset to use for `cross_validate()` but was later clarified by the prof.\n",
    "- It was very interesting to see how the scalers and hyperparameter-tweaking made the `SVC()` model a lot better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "results_dict_3 = {\n",
    "    \"Model\": [\"LinearSVC\"],\n",
    "    \"X size\": [],\n",
    "    \"y size\": [],\n",
    "    \"Accuracy (Training)\" : [],\n",
    "    \"Accuracy (Testing)\" : []\n",
    "}\n",
    "\n",
    "linear_svm_model = LinearSVC(max_iter=5000, random_state=0)\n",
    "linear_svm_model.fit(X_train, y_train)\n",
    "cv_result_LSVM = cross_validate(linear_svm_model, X_train, y_train.values.ravel(), scoring='accuracy', return_train_score=True)\n",
    "\n",
    "results_dict_3[\"X size\"].append(X.shape)\n",
    "results_dict_3[\"y size\"].append(y.shape)\n",
    "\n",
    "LSVM_score_test = cv_result_LSVM['test_score'].mean()\n",
    "LSVM_score_train = cv_result_LSVM['train_score'].mean()\n",
    "# print(acc_score_test)\n",
    "results_dict_3[\"Accuracy (Testing)\"].append(LSVM_score_test)\n",
    "results_dict_3[\"Accuracy (Training)\"].append(LSVM_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "#### ANSWER: ####\n",
    "\n",
    "`LinearSVC(max_iter=5000)` gives good results based on the training and testing accuracy scores, but is not as effective as the `DecisionTreeClassifier(max_depth=3)` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>X size</th>\n",
       "      <th>y size</th>\n",
       "      <th>Accuracy (Training)</th>\n",
       "      <th>Accuracy (Testing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>(178, 13)</td>\n",
       "      <td>(178, 1)</td>\n",
       "      <td>0.868295</td>\n",
       "      <td>0.849858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     X size    y size  Accuracy (Training)  Accuracy (Testing)\n",
       "0  LinearSVC  (178, 13)  (178, 1)             0.868295            0.849858"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_3 = pd.DataFrame(results_dict_3)\n",
    "results_df_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
