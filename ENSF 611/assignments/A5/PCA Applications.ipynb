{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning - dimensionality reduction\n",
    "## Applications of Principal component analysis PCA\n",
    "\n",
    "Follow:\n",
    "- _Introduction to Machine Learning_ [Chapter 3](https://github.com/amueller/introduction_to_ml_with_python/blob/master/03-unsupervised-learning.ipynb) **Section 3.4.1 Principal Component Analysis** (p.149-155)\n",
    "- _Python Data Science Handbook_ [Chapter 5 In Depth: Principal Components Analysis](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb) (p.437-442)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for visualization: Handwritten digit dataset\n",
    "code from Python Data Science Handbook Chapter 5:[Principal Component Analysis](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb)\n",
    "\n",
    "8x8 images of handwritten digits are stored as vectors of length 64. Each vector component (pixel) is a feature. All image vectors are stacked in a feature matrix X. How to visualize this dataset with 64 columns?\n",
    "\n",
    "Use PCA to reduce to 2 dimensions and plot rows in this new 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)  # project from 64 to 2 dimensions\n",
    "projected = pca.fit_transform(digits.data)\n",
    "print(digits.data.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(pca.explained_variance_ratio_, index=['PCA1', 'PCA2']).plot.bar(legend=False, figsize=(4,4))\n",
    "ax.set_title('Explained variance ratio (R2)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=digits.target, \n",
    "            cmap=plt.cm.get_cmap('Spectral', 10),\n",
    "            edgecolor='none', \n",
    "            alpha=0.5)\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import offsetbox\n",
    "\n",
    "def plot_components(data, model, images=None, ax=None,\n",
    "                    thumb_frac=0.05, zoom =1, cmap='gray'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    proj = model.fit_transform(data)\n",
    "    ax.plot(proj[:, 0], proj[:, 1], '.k')\n",
    "    ax.set_xlabel('First principal component')\n",
    "    ax.set_ylabel('Second principal component')\n",
    "    \n",
    "    if images is not None:\n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        for i in range(data.shape[0]):\n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < min_dist_2:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.vstack([shown_images, proj[i]])\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(images[i], zoom=zoom,cmap=cmap),\n",
    "                                      proj[i])\n",
    "            ax.add_artist(imagebox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_components(digits.data,\n",
    "                model=pca,\n",
    "                images=digits.data.reshape((-1, 8, 8)),\n",
    "                ax=ax, thumb_frac=0.05, zoom=3, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many components should we choose?\n",
    "\n",
    "For visualization, we can at most choose 3.\n",
    "\n",
    "For feature engineering, we would choose the number necessary to explain a defined amount of variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(digits.data)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.grid(True)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for feature extraction: Eigenfaces\n",
    "Introduction to Machine Learning with Python [Chapter 3.4.1](https://github.com/amueller/introduction_to_ml_with_python/blob/master/03-unsupervised-learning.ipynb)\n",
    "\n",
    "This example aims to identify the person with an face image:\n",
    "- 1-NN classifier: Builds a database of known faces\n",
    "- Given a new image, the name associated with the closest image is returned.\n",
    "- The *Labeled Faces in the Wild* dataset has face images of 62 people\n",
    "- Randomly guessing would give an accuracy of 1/62=1.6%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled faces in the wild dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)\n",
    "image_shape = people.images[0].shape\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8),\n",
    "                         subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for target, image, ax in zip(people.target, people.images, axes.ravel()):\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(people.target_names[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"people.images.shape: {}\".format(people.images.shape))\n",
    "print(\"Number of classes: {}\".format(len(people.target_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how often each target appears\n",
    "counts = np.bincount(people.target)\n",
    "# print counts next to target names:\n",
    "for i, (count, name) in enumerate(zip(counts, people.target_names)):\n",
    "    print(\"{0:25} {1:3}\".format(name, count), end='   ')\n",
    "    if (i + 1) % 3 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "- Select at most 50 images from all people.\n",
    "- Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(people.target.shape, dtype=bool)\n",
    "for target in np.unique(people.target):\n",
    "    mask[np.where(people.target == target)[0][:50]] = 1\n",
    "    \n",
    "X_people = people.data[mask]\n",
    "y_people = people.target[mask]\n",
    "\n",
    "# scale the grey-scale values to be between 0 and 1\n",
    "# instead of 0 and 255 for better numeric stability:\n",
    "X_people = X_people / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_people.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.target_names[y_people]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "plt.imshow(X_people[idx,:].reshape(image_shape), cmap='gray')\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(people.target_names[y_people[idx]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the closest face using 1-nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split the data in training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_people, y_people, stratify=y_people, random_state=0)\n",
    "\n",
    "print(f\"Training set shape= {X_train.shape}\")\n",
    "print(f\"Test set shape={X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a KNeighborsClassifier with using one neighbor:\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Test set score of 1-nn: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We obtain an accuracy of 23%, which is not actually that bad for a 62-class classification problem (random guessing would give you around 1/62 = 1.6% accuracy), but is also not great. We only correctly identify a person every fourth time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN uses distance. Does a different normalization help?\n",
    "Let's use the original data, which is normalized to [0,1] and scale it with a `StandardScaler`, then pass to 1-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# build a KNeighborsClassifier with using one neighbor:\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_scaled.fit(X_train_scaled, y_train)\n",
    "print(\"Test set score of 1-nn with scaled features: {:.2f}\".format(knn_scaled.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yes, StandardScaling helps, increasing accuracy from 23% to 26%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features with PCA\n",
    "\n",
    "With PCA we can:\n",
    "1. Find a better basis and reduced the number of features,\n",
    "2. *Whiten* the data which has the same effect as applying a `StandardScaler` **after** PCA transformation. In oother words: PCA+Whiten = PCA + StandardScaler\n",
    "\n",
    "We saw that scaled features improves performance and we can, hopefully, further improve by using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_pca_whitening()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, whiten=True, random_state=0).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(\"X_train_pca.shape: {}\".format(X_train_pca.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "print(\"Test set accuracy: {:.2f}\".format(knn.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA with whitening improves the accuracy to 31%, surprisingly with only 100 features, as compared to >5000 features initially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#TODO: reduce the number of labels\n",
    "mat = confusion_matrix(y_test, knn.predict(X_test_pca))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,12))\n",
    "sns.heatmap(mat, annot=True, fmt='d', cbar=False, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA for noise reduction \n",
    "code from Python Data Science Handbook Chapter 5:[Principal Component Analysis](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(data):\n",
    "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(8, 8),\n",
    "                  cmap='binary', interpolation='nearest',\n",
    "                  clim=(0, 16))\n",
    "plot_digits(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy = np.random.normal(digits.data, 4)\n",
    "plot_digits(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising with PCA\n",
    "\n",
    "Assumption: Most of the variance is due to the signal, components with smaller eigenvalues (explained variance) are the noise components.\n",
    "\n",
    "**Note:** when we pass a float value between 0 and 1 to PCA in the `n_components` parameter, we ask PCA to determine the number of components that explains at least `n_components` percent, i.e. passing 0.5 we would like to explain 50% of the variance.\n",
    "\n",
    "Here, 12 components are needed. We reduce from 64 dimensions to 12.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.60).fit(noisy)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For denoising, we:\n",
    "1. Project to reduced space `transform()`\n",
    "2. Transform back to original space `inverse_transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.transform(noisy)\n",
    "filtered = pca.inverse_transform(components)\n",
    "plot_digits(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
