{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a89ecb",
   "metadata": {},
   "source": [
    "# Unsupervised learning - dimensionality reduction\n",
    "## Non-linear methods for dimensionality reduction - Manifold learning\n",
    "\n",
    "Follow:\n",
    "- _Python Data Science Handbook_ [Chapter 5 In Depth: Manifold learning](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.10-Manifold-Learning.ipynb) (p.445-455)\n",
    "- _Introduction to Machine Learning_ [Chapter 3](https://github.com/amueller/introduction_to_ml_with_python/blob/master/03-unsupervised-learning.ipynb) **Section 3.4.3 Manifold Learning with t-SNE** (p.165-170)\n",
    "\n",
    "\n",
    "PCA reduces dimension by projection onto hyperplanes. It is a linear method.\n",
    "\n",
    "An alternative is to perform Manifold learning, a non-linear technique.\n",
    "\n",
    "A word of caution:\n",
    ">... in practice manifold learning techniques tend to be finicky enough that they are rarely used for anything more than simple qualitative visualization of high-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4296e7",
   "metadata": {},
   "source": [
    "## What is manifold learning?\n",
    "\n",
    "Python Data Science Handbook Chapter 5: Manifold Learning\n",
    "\n",
    ">We have seen how principal component analysis can be used in the dimensionality reduction task—reducing the number of features of a dataset while maintaining the essential relationships between the points. While PCA is flexible, fast, and easily interpretable, it does not perform so well when there are nonlinear relationships within the data; we will see some examples of these below.\n",
    "\n",
    ">To address this deficiency, we can turn to a class of methods known as manifold learning—a class of unsupervised estimators that seeks to describe datasets as low-dimensional manifolds embedded in high-dimensional spaces. When you think of a manifold, I’d suggest imagining a sheet of paper: this is a two-dimensional object that lives in our familiar three-dimensional world, and can be bent or rolled in two dimensions. In the parlance of manifold learning, we can think of this sheet as a two-dimensional manifold embedded in three-dimensional space.\n",
    "\n",
    ">Rotating, reorienting, or stretching the piece of paper in three-dimensional space doesn’t change the flat geometry of the paper: such operations are akin to linear embeddings. If you bend, curl, or crumple the paper, it is still a two-dimensional manifold, but the embedding into the three-dimensional space is no longer linear. Manifold learning algorithms would seek to learn about the fundamental two-dimensional nature of the paper, even as it is contorted to fill the three-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b5d81",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "From _Hands on Machine learning with scikit-learn_ Chapter 8 Dimensionality Reduction:\n",
    ">t-Distributed Stochastic Neighbor Embedding (t-SNE) reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It is mostly used for visualization, in particular to visualize clusters of instances in high-dimensional space (e.g., to visualize the MNIST images in 2D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a880924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5),\n",
    "                         subplot_kw={'xticks':(), 'yticks': ()})\n",
    "for ax, img in zip(axes.ravel(), digits.images):\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f5f76",
   "metadata": {},
   "source": [
    "Let’s use PCA to visualize the data reduced to two dimensions. We plot the first two principal components, and represent each sample with a digit corresponding to its class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8498d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a PCA model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(digits.data)\n",
    "# transform the digits data onto the first two principal components\n",
    "digits_pca = pca.transform(digits.data)\n",
    "colors = [\"#476A2A\", \"#7851B8\", \"#BD3430\", \"#4A2D4E\", \"#875525\",\n",
    "          \"#A83683\", \"#4E655E\", \"#853541\", \"#3A3120\", \"#535D8E\"]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(digits_pca[:, 0].min(), digits_pca[:, 0].max())\n",
    "plt.ylim(digits_pca[:, 1].min(), digits_pca[:, 1].max())\n",
    "for i in range(len(digits.data)):\n",
    "    # actually plot the digits as text instead of using scatter\n",
    "    plt.text(digits_pca[i, 0], digits_pca[i, 1], str(digits.target[i]),\n",
    "             color = colors[digits.target[i]],\n",
    "             fontdict={'weight': 'bold', 'size': 9})\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81caf0",
   "metadata": {},
   "source": [
    "Here, we actually used the true digit classes as glyphs, to show which class is where. The digits zero, six, and four are relatively well separated using the first two principal components, though they still overlap. Most of the other digits overlap significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f97590",
   "metadata": {},
   "source": [
    "Let’s apply t-SNE to the same dataset, and compare the results. As t-SNE does not support transforming new data, the `TSNE` class has no `transform` method. Instead, we can call the `fit_transform` method, which will build the model and immediately return the transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d181817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=42)\n",
    "# use fit_transform instead of fit, as TSNE has no transform method\n",
    "digits_tsne = tsne.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86443ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(digits_tsne[:, 0].min(), digits_tsne[:, 0].max() + 1)\n",
    "plt.ylim(digits_tsne[:, 1].min(), digits_tsne[:, 1].max() + 1)\n",
    "for i in range(len(digits.data)):\n",
    "    # actually plot the digits as text instead of using scatter\n",
    "    plt.text(digits_tsne[i, 0], digits_tsne[i, 1], str(digits.target[i]),\n",
    "             color = colors[digits.target[i]],\n",
    "             fontdict={'weight': 'bold', 'size': 9})\n",
    "plt.xlabel(\"t-SNE feature 0\")\n",
    "plt.ylabel(\"t-SNE feature 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d795f2",
   "metadata": {},
   "source": [
    "The result of t-SNE is quite remarkable. All the classes are quite clearly separated. The ones and nines are somewhat split up, but most of the classes form a single dense group. Keep in mind that this method has no knowledge of the class labels: it is completely unsupervised. Still, it can find a representation of the data in two dimensions that clearly separates the classes, based solely on how close points are in the original space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd1a84",
   "metadata": {},
   "source": [
    "## Isomap\n",
    "\n",
    "From _Hands on Machine learning with scikit-learn_ Chapter 8 Dimensionality Reduction:\n",
    "> Isomap creates a graph by connecting each instance to its nearest neighbors, then reduces dimensionality while trying to preserve the geodesic distances between the instances. The geodesic distance between two nodes in a graph is the number of nodes on the shortest path between these nodes\n",
    "\n",
    "Code from Python Data Science Handbook Chapter 5: [Manifold Learning](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.10-Manifold-Learning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd300c",
   "metadata": {},
   "source": [
    "### Labeled faces in the wild dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=30)\n",
    "faces.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57886fa",
   "metadata": {},
   "source": [
    "### PCA needs many components - relationship might be non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15710eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "model = PCA(100, svd_solver='randomized', random_state=88).fit(faces.data)\n",
    "plt.plot(np.cumsum(model.explained_variance_ratio_))\n",
    "plt.xlabel('n components')\n",
    "plt.ylabel('cumulative variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553aae3",
   "metadata": {},
   "source": [
    "### Isomap for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5523657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "model = Isomap(n_components=2)\n",
    "proj = model.fit_transform(faces.data)\n",
    "proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import offsetbox\n",
    "\n",
    "def plot_components(data, model, images=None, ax=None,\n",
    "                    thumb_frac=0.05, zoom =1, cmap='gray'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    proj = model.fit_transform(data)\n",
    "    ax.plot(proj[:, 0], proj[:, 1], '.k')\n",
    "    \n",
    "    if images is not None:\n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        for i in range(data.shape[0]):\n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < min_dist_2:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.vstack([shown_images, proj[i]])\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(images[i], zoom=zoom,cmap=cmap),\n",
    "                                      proj[i])\n",
    "            ax.add_artist(imagebox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ed017",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_components(faces.data,\n",
    "                model=Isomap(n_components=2),\n",
    "                images=faces.images[:, ::2, ::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05bff57",
   "metadata": {},
   "source": [
    ">The result is interesting: the first two Isomap dimensions seem to describe global image features: the overall darkness or lightness of the image from left to right, and the general orientation of the face from bottom to top. This gives us a nice visual indication of some of the fundamental features in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ee210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
