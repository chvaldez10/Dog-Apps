{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics\n",
    "Due Date: October 10, 2023\n",
    "<br>\n",
    "<br>\n",
    "Name: Christian Valdez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset\n",
    "import yellowbrick\n",
    "from yellowbrick.datasets import load_spam, load_concrete\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33583c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spam dataset from yellowbrick library\n",
    "X, y = yellowbrick.datasets.loaders.load_spam(\n",
    "    data_home=None, return_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18bfd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4600 samples and 57 features.\n",
      "The size of the feature matrix is 262200.\n"
     ]
    }
   ],
   "source": [
    "# print size of X\n",
    "rows, cols = X.shape\n",
    "data_size = X.size\n",
    "print(f\"There are {rows} samples and {cols} features.\\nThe size of the feature matrix is {data_size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d23ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature matrix comes with the corresponding 4600 labels.\n",
      "0 indicating a not spam email (ham) and 1 for a spam email.\n"
     ]
    }
   ],
   "source": [
    "# print size of y\n",
    "rows, = y.shape\n",
    "print(f\"The feature matrix comes with the corresponding {rows} labels.\\n0 indicating a not spam email (ham) and 1 for a spam email.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd440e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type for features: \n",
      "word_freq_make: float64\n",
      "word_freq_address: float64\n",
      "word_freq_all: float64\n",
      "word_freq_3d: float64\n",
      "word_freq_our: float64\n",
      "word_freq_over: float64\n",
      "word_freq_remove: float64\n",
      "word_freq_internet: float64\n",
      "word_freq_order: float64\n",
      "word_freq_mail: float64\n",
      "word_freq_receive: float64\n",
      "word_freq_will: float64\n",
      "word_freq_people: float64\n",
      "word_freq_report: float64\n",
      "word_freq_addresses: float64\n",
      "word_freq_free: float64\n",
      "word_freq_business: float64\n",
      "word_freq_email: float64\n",
      "word_freq_you: float64\n",
      "word_freq_credit: float64\n",
      "word_freq_your: float64\n",
      "word_freq_font: float64\n",
      "word_freq_000: float64\n",
      "word_freq_money: float64\n",
      "word_freq_hp: float64\n",
      "word_freq_hpl: float64\n",
      "word_freq_george: float64\n",
      "word_freq_650: float64\n",
      "word_freq_lab: float64\n",
      "word_freq_labs: float64\n",
      "word_freq_telnet: float64\n",
      "word_freq_857: float64\n",
      "word_freq_data: float64\n",
      "word_freq_415: float64\n",
      "word_freq_85: float64\n",
      "word_freq_technology: float64\n",
      "word_freq_1999: float64\n",
      "word_freq_parts: float64\n",
      "word_freq_pm: float64\n",
      "word_freq_direct: float64\n",
      "word_freq_cs: float64\n",
      "word_freq_meeting: float64\n",
      "word_freq_original: float64\n",
      "word_freq_project: float64\n",
      "word_freq_re: float64\n",
      "word_freq_edu: float64\n",
      "word_freq_table: float64\n",
      "word_freq_conference: float64\n",
      "char_freq_;: float64\n",
      "char_freq_(: float64\n",
      "char_freq_[: float64\n",
      "char_freq_!: float64\n",
      "char_freq_$: float64\n",
      "char_freq_#: float64\n",
      "capital_run_length_average: float64\n",
      "capital_run_length_longest: int64\n",
      "capital_run_length_total: int64\n"
     ]
    }
   ],
   "source": [
    "# feature data type of X\n",
    "print(\"Data type for features: \", )\n",
    "for feature, dtype in X.dtypes.items():\n",
    "    print(f\"{feature}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2808ad4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type for labels:  int64\n"
     ]
    }
   ],
   "source": [
    "# feature data type of y\n",
    "print(\"Data type for labels: \", y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db37c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in X.\n",
      "There are no missing values in y.\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "missing_values_X = X.isnull().sum().sum()\n",
    "missing_values_y = y.isnull().sum()\n",
    "\n",
    "if missing_values_X != 0:\n",
    "    X.fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in X. Total filled: {missing_values_X}\")\n",
    "else:\n",
    "    print(\"There are no missing values in X.\")\n",
    "\n",
    "if missing_values_y != 0:\n",
    "    y.fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in y. Total filled: {missing_values_y}\")\n",
    "else:\n",
    "    print(\"There are no missing values in y.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 230\n",
      "Test set size: 230\n"
     ]
    }
   ],
   "source": [
    "# split data with test size 5% of the data\n",
    "X_train, X_small, y_train, y_small = train_test_split(\n",
    "    X, y, test_size=0.05, random_state=0)\n",
    "\n",
    "print(f\"Training set size: {len(X_small)}\")\n",
    "print(f\"Test set size: {len(y_small)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Full Dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with First Two Columns\n",
      "Training with 5% of the dataset\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# get the first two columns\n",
    "x_first_two_columns = X.iloc[:, :2]\n",
    "x_first_two_columns.head()\n",
    "\n",
    "# results dataframe\n",
    "results = {\n",
    "    \"Data Size\": [],\n",
    "    \"Training Accuracy\": [],\n",
    "    \"Validation Accuracy\": []\n",
    "}\n",
    "\n",
    "# datasets\n",
    "X_datasets = [X, x_first_two_columns, X_small]\n",
    "X_labels = [y, y, y_small]\n",
    "X_dataset_names = [\"Full Dataset\", \"First Two Columns\", \"5% of the dataset\"]\n",
    "\n",
    "for dataset_num in range(3):\n",
    "    row, col = X_datasets[dataset_num].shape\n",
    "\n",
    "    print(f\"Training with {X_dataset_names[dataset_num]}\")\n",
    "    x1, x2, y1, y2 = train_test_split(X_datasets[dataset_num], X_labels[dataset_num], test_size=0.2, random_state=0)\n",
    "\n",
    "    # instantiate the model\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    # train the dataset\n",
    "    model.fit(x1, y1)\n",
    "\n",
    "    # training accuracy\n",
    "    training_score = model.score(x1, y1)\n",
    "\n",
    "    # validation accuracy\n",
    "    validation_score = model.score(x2, y2)\n",
    "\n",
    "    # appends to results table\n",
    "    results[\"Data Size\"].append(row*col)\n",
    "    results[\"Training Accuracy\"].append(training_score)\n",
    "    results[\"Validation Accuracy\"].append(validation_score)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.index = X_dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0274ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Dataset</th>\n",
       "      <td>262200</td>\n",
       "      <td>0.927989</td>\n",
       "      <td>0.936957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Two Columns</th>\n",
       "      <td>9200</td>\n",
       "      <td>0.614946</td>\n",
       "      <td>0.593478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5% of the dataset</th>\n",
       "      <td>13110</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.804348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Data Size  Training Accuracy  Validation Accuracy\n",
       "Full Dataset          262200           0.927989             0.936957\n",
       "First Two Columns       9200           0.614946             0.593478\n",
       "5% of the dataset      13110           0.956522             0.804348"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "\n",
    "With the full dataset, the training and validation accuracies are quite similar, registering at **0.928** and **0.937** respectively. Interestingly, the training accuracy is slightly lower, possibly suggesting that the training data might be more intricate than the validation set. \n",
    "\n",
    "Using only 5% of the data, there's a noticeable divergence between the training and validation accuracies — **0.957** versus **0.804**. This disparity suggests potential overfitting.\n",
    "\n",
    "Reducing the features yields diminished accuracies for both training and validation, recorded at **0.615** and **0.593**, respectively.\n",
    "\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "A false positive indicates that the model erroneously labeled an email as spam when it wasn't. Conversely, a false negative means the model missed identifying a genuine spam email. The latter, false negatives, are more detrimental since overlooking spam emails can introduce security risks. While mislabeling a genuine email as spam isn't ideal, it's less concerning than the alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I used ChatGPT to review my code and help clarify some questions. Also, I used common Python documentation websites to search for built in functions.\n",
    "\n",
    "- [ChatGPT](https://chat.openai.com/share/06987052-fc84-4545-8c0b-ef26077cca12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  dataset\n",
    "X, y = yellowbrick.datasets.loaders.load_concrete(\n",
    "    data_home=None, return_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a25a617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1030 samples and 8 features.\n",
      "The size of the feature matrix is 8240.\n"
     ]
    }
   ],
   "source": [
    "# feature matrix\n",
    "rows, cols = X.shape\n",
    "data_size = X.size\n",
    "print(\n",
    "    f\"There are {rows} samples and {cols} features.\\nThe size of the feature matrix is {data_size}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in X.\n",
      "There are no missing values in y.\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "missing_values_X = X.isnull().sum().sum()\n",
    "missing_values_y = y.isnull().sum()\n",
    "\n",
    "if missing_values_X != 0:\n",
    "    X.fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in X. Total filled: {missing_values_X}\")\n",
    "else:\n",
    "    print(\"There are no missing values in X.\")\n",
    "\n",
    "if missing_values_y != 0:\n",
    "    y.fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in y. Total filled: {missing_values_y}\")\n",
    "else:\n",
    "    print(\"There are no missing values in y.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b3df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Linear Regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaaa65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data train = 80%, test = 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f6f32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# train model\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "linear_prediction_train = linear_model.predict(X_train)\n",
    "linear_prediction_test = linear_model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "mse_train = mean_squared_error(y_train, linear_prediction_train)\n",
    "mse_test = mean_squared_error(y_test, linear_prediction_test)\n",
    "\n",
    "# Compute and print the R^2 score\n",
    "r2_train = r2_score(y_train, linear_prediction_train)\n",
    "r2_test = r2_score(y_test, linear_prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lr = {\n",
    "    \"Training Accuracy\": [mse_train, r2_train],\n",
    "    \"Validation Accuracy\": [mse_test, r2_test]\n",
    "}\n",
    "results_lr = pd.DataFrame(results_lr)\n",
    "results_lr.index = [\"MSE\", \"R2 Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dc179ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training Accuracy  Validation Accuracy\n",
       "MSE              111.358439            95.904136\n",
       "R2 Score           0.610823             0.623414"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47623d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train a Ridge regression model\n",
    "ridge_model = Ridge(alpha=100)  # You can tune the alpha parameter\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "ridge_prediction_train = ridge_model.predict(X_train)\n",
    "ridge_prediction_test = ridge_model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "mse_train = mean_squared_error(y_train, ridge_prediction_train)\n",
    "mse_test = mean_squared_error(y_test, ridge_prediction_test)\n",
    "\n",
    "# Compute and print the R^2 score\n",
    "r2_train = r2_score(y_train, ridge_prediction_train)\n",
    "r2_test = r2_score(y_test, ridge_prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad916136",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ridge = {\n",
    "    \"Training Accuracy\": [mse_train, r2_train],\n",
    "    \"Validation Accuracy\": [mse_test, r2_test]\n",
    "}\n",
    "results_ridge = pd.DataFrame(results_ridge)\n",
    "results_ridge.index = [\"MSE\", \"R2 Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5c74370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.358548</td>\n",
       "      <td>95.894268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training Accuracy  Validation Accuracy\n",
       "MSE              111.358548            95.894268\n",
       "R2 Score           0.610823             0.623453"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d118c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e+04, tolerance: 2.209e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a Lasso regression model\n",
    "lasso_model = Lasso(alpha=1e-4, max_iter=100)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "lasso_prediction_train = lasso_model.predict(X_train)\n",
    "lasso_prediction_test = lasso_model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "mse_train = mean_squared_error(y_train, lasso_prediction_train)\n",
    "mse_test = mean_squared_error(y_test, lasso_prediction_test)\n",
    "\n",
    "# Compute and print the R^2 score\n",
    "r2_train = r2_score(y_train, lasso_prediction_train)\n",
    "r2_test = r2_score(y_test, lasso_prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2be654a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lasso = {\n",
    "    \"Training Accuracy\": [mse_train, r2_train],\n",
    "    \"Validation Accuracy\": [mse_test, r2_test]\n",
    "}\n",
    "results_lasso = pd.DataFrame(results_lasso)\n",
    "results_lasso.index = [\"MSE\", \"R2 Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "191ff95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.358450</td>\n",
       "      <td>95.899893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training Accuracy  Validation Accuracy\n",
       "MSE              111.358450            95.899893\n",
       "R2 Score           0.610823             0.623431"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
