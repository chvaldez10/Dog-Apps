{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart disease clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_heart_disease():\n",
    "    '''Load and pre-process heart disease data\n",
    "    \n",
    "    if processed.hungarian.data file is not present.\n",
    "    \n",
    "    it will be downloaded from\n",
    "    https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\n",
    "    \n",
    "    return: data(DataFrame)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    \n",
    "    file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "    file_name = file_url.split('/')[-1]\n",
    "    \n",
    "    if not os.path.isfile(file_name):\n",
    "        print('Downloading from {}'.format(file_url))\n",
    "        r = requests.get(file_url)\n",
    "        with open(file_name,'wb') as output_file:\n",
    "            output_file.write(r.content)\n",
    "        \n",
    "    data = pd.read_csv(file_name, \n",
    "                   na_values='?', \n",
    "                   names=[ 'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',\n",
    "                            'restecg', 'thalach', 'exang', 'oldpeak', 'slope',\n",
    "                            'ca', 'thal', 'num'])\n",
    "    \n",
    "    data = data[['age', 'trestbps', 'chol', 'thalach']]\n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_heart_disease()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(df)\n",
    "X_2D = pca.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_2D[:, 0], X_2D[:, 1])\n",
    "plt.xlabel('PCA0')\n",
    "plt.ylabel('PCA1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering\n",
    "\n",
    "There are a few questions that we must answer before we start clustering:\n",
    "\n",
    "1. Do we need to process the data first?\n",
    "1. How many clusters should we use?\n",
    "1. Which method should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "df = load_heart_disease()\n",
    "df_scaled = df.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_scaled)\n",
    "df_scaled = pd.DataFrame(scaler.transform(df_scaled), columns=df_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=54)\n",
    "kmeans.fit(df_scaled)\n",
    "\n",
    "df['clusters'] = kmeans.labels_\n",
    "df['clusters'] = df['clusters'].astype('category') #makes seaborn use qualitative color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=df_scaled.columns)\n",
    "centers_scaled = pd.DataFrame(kmeans.cluster_centers_, columns=df_scaled.columns)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax = sns.scatterplot(x='age', y='trestbps', hue='clusters', ax=ax, data=df)\n",
    "\n",
    "centers.plot.scatter(x='age', y='trestbps', ax=ax, marker='x', s=80, color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(kmeans.labels_)\n",
    "print(counts)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(counts.values(), labels=[f'Cluster {i}' for i in counts.keys()], autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal');  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title('Cluster size distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Clusters are not really balanced, one cluster takes half of the patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(kmeans.n_clusters, 1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    center = centers_scaled.loc[i, :]\n",
    "    maxPC = 1.01 * np.max(np.max(np.abs(center)))\n",
    "    colors = ['C0' if l>0 else 'C1' for l in center]\n",
    "    ax.axhline(color='#888888')\n",
    "    center.plot.bar(ax=ax, color=colors)\n",
    "    ax.set_ylabel(f'Cluster{i}')\n",
    "    ax.set_ylim(-maxPC, maxPC)\n",
    "    if i == 0:\n",
    "        ax.set_title('Cluster centers per feature on standard scale')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Typically, it is adviced to back transform the centers to original scale. It seems to me that leaving them on the standard scales helps interpretation.\n",
    "\n",
    "For example, in the plot above, _Cluster 0_ contains patients with age well bellow the average -> young individuals; _Cluster 1_ on the other hand has patients with age well above average -> older individuals. Finally, _Cluster 2_ has average age patients with high cholesterol and high blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, kmeans.n_clusters, figsize=(9, 3), sharey=True)\n",
    "\n",
    "overall_max = centers.max().max()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    center = centers.loc[i, :]\n",
    "\n",
    "    colors = ['C0' if l>0 else 'C1' for l in center]\n",
    "    ax.axhline(color='#888888')\n",
    "    center.plot.bar(ax=ax, color=colors)\n",
    "    ax.set_title(f'Cluster{i}')\n",
    "    ax.set_ylim(0, overall_max)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Center, original scale')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Number of Clusters\n",
    "\n",
    "We can use the elbow method to check the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster.elbow import kelbow_visualizer\n",
    "kelbow_visualizer(KMeans(random_state=54), df_scaled, k=(2,10), \n",
    "                  metric='distortion',\n",
    "                 timings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelbow_visualizer(KMeans(random_state=54), df_scaled, k=(2,10), \n",
    "                  metric='silhouette',\n",
    "                 timings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelbow_visualizer(KMeans(random_state=54), df_scaled, k=(2,10), \n",
    "                  metric='calinski_harabasz',\n",
    "                 timings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
