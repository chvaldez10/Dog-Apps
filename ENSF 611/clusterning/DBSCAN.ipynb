{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2a68d8-0736-4c1a-b7dd-2c14195db96e",
   "metadata": {},
   "source": [
    "# Unsupervised learning - Clustering\n",
    "## DBSCAN\n",
    "\n",
    "Follow:\n",
    "- _Introduction to Machine Learning_ [Chapter 3](https://github.com/amueller/introduction_to_ml_with_python/blob/master/03-unsupervised-learning.ipynb) **Section 3.5.3 DBSCAN** (p.189-193)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4855a-e1aa-442f-958a-d147c5c09af1",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    ">The idea behind DBSCAN is that clusters form dense regions of data, separated by regions that are relatively empty\n",
    "\n",
    "Assigns points to clusters automatically, no need to choose the number of clusters\n",
    "\n",
    "\n",
    "\n",
    "Two parameters: `eps` and `min_samples`\n",
    "\n",
    ">Points that are within a dense region are called core samples (or core points), and they are defined as follows. There are two parameters in DBSCAN: min_samples and eps. If there are at least min_samples many data points within a distance of eps to a given data point, that data point is classified as a core sample. Core samples that are closer to each other than the distance eps are put into the same cluster by DBSCAN\n",
    "\n",
    "There is a *noise* cluster\n",
    ">If there are less than min_samples points within distance eps of the starting point, this point is labeled as noise, meaning that it doesnâ€™t belong to any cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bc93a-4189-421f-94a5-bfc8be626069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import DBSCAN\n",
    "X, y = make_blobs(random_state=0, n_samples=12)\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X)\n",
    "print(\"Cluster memberships:\\n{}\".format(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf85234-19b0-424b-9fa2-c378291e711e",
   "metadata": {},
   "source": [
    "Parameters **need** to be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26904346-66b8-44c3-9d8d-37f173be16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_dbscan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31021058-ca60-46f7-a3c8-4e5b76a3658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "# Rescale the data to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "# plot the cluster assignments\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=mglearn.cm2, s=60)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed08438-5ad6-4cda-864b-19b568c27081",
   "metadata": {},
   "source": [
    "## DBSCAN on Wine dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e0c1a-a9c3-483d-88d5-47166f8a21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X, _ = load_wine(return_X_y=True, as_frame=True)\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15196f-5b2b-47ca-b763-509e6864500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [0.5, 1, 1.5, 2, 2.5, 3]:\n",
    "    for min_samples in [2, 3, 4, 5, 6, 7, 8, 9, 10 ]:\n",
    "        \n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(X)\n",
    "        num = len(np.unique(labels))\n",
    "        if 1 < num < 7:\n",
    "            print(\"\\neps={} min_samples={}\".format(eps, min_samples))\n",
    "            print(\"Number of clusters: {}\".format(num))\n",
    "            print(\"Cluster sizes: {}\".format(np.bincount(labels + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f6d6f-fc42-4147-aa74-bf72782cd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=2, min_samples=8)\n",
    "X['clusters'] = dbscan.fit_predict(X)\n",
    "X['clusters'] = X['clusters'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12260ac6-3711-4bdd-9b16-c9c38b6978dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_2D = pca.transform(X)\n",
    "sns.scatterplot(x=X_2D[:,0], y=X_2D[:,1], hue=X['clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cac44f-050e-468f-bbd2-27488e707372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
