{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Classifier üóëÔ∏è üöÆ üöØ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import wandb\n",
    "import torch\n",
    "from glob import glob\n",
    "import matplotlib.pylab as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms, models\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EPOCHS = 12\n",
    "LEARNING_RATE = 2e-4\n",
    "TEST_SPLIT = 0.2\n",
    "VAL_SPLIT = 0.2\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 4\n",
    "INPUT_SHAPE = (3, 224, 224)\n",
    "INPUT_SIZE = (1, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "DATASET_LOCAL_PATH=\"/Users/redge/Library/CloudStorage/OneDrive-UniversityofCalgary/School/MEng/Winter2024/enel645/ENSF-611-ENEL-645/ENEL 645/A2/small_dataset\"\n",
    "DATASET_REMOTE_PATH=\"/work/TALC/enel645_2024w/CVPR_2024_dataset\"\n",
    "MODEL_PATH=\"/Users/redge/Library/CloudStorage/OneDrive-UniversityofCalgary/School/MEng/Winter2024/enel645/ENSF-611-ENEL-645/ENEL 645/A2/best_dataset/garbage_net.pth\"\n",
    "\n",
    "dataset_path = DATASET_LOCAL_PATH\n",
    "normalized_path = dataset_path\n",
    "best_model_path = MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚Üª Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from dataset_loader.py\n",
    "\n",
    "def list_images(images_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    List all images in the given path.\n",
    "    \"\"\"\n",
    "    images = glob(images_path, recursive=True)\n",
    "    return np.array(images)\n",
    "\n",
    "def extract_labels(images: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract labels from image paths.\n",
    "    \"\"\"\n",
    "    labels = np.array([f.replace(\"\\\\\", \"/\").split(\"/\")[-2] for f in images])\n",
    "    classes = np.unique(labels)\n",
    "    return labels, classes\n",
    "\n",
    "def convert_labels_to_int(labels: np.ndarray, classes: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert string labels to integers.\n",
    "    \"\"\"\n",
    "    label_to_int = {label: i for i, label in enumerate(classes)}\n",
    "    labels_int = np.array([label_to_int[label] for label in labels])\n",
    "    return labels_int\n",
    "\n",
    "def list_data_and_prepare_labels(images_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    List all images, extract labels, and prepare them for training.\n",
    "    \"\"\"\n",
    "    images = list_images(images_path)\n",
    "    labels, classes = extract_labels(images)\n",
    "    labels_int = convert_labels_to_int(labels, classes)\n",
    "    return images, labels_int, classes\n",
    "\n",
    "def split_data(images: np.ndarray, labels: np.ndarray, val_split: float, test_split: float, random_state: int = 10) -> tuple:\n",
    "    \"\"\"\n",
    "    Split data into train, validation, and test sets and return them as dictionaries.\n",
    "    \"\"\"\n",
    "    # Splitting the data into dev and test sets\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_split, random_state=random_state)\n",
    "    dev_index, test_index = next(sss.split(images, labels))\n",
    "    dev_images, dev_labels = images[dev_index], labels[dev_index]\n",
    "    test_images, test_labels = images[test_index], labels[test_index]\n",
    "\n",
    "    # Splitting the data into train and val sets\n",
    "    val_size = int(val_split * len(images))\n",
    "    val_split_adjusted = val_size / len(dev_images)\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=val_split_adjusted, random_state=random_state)\n",
    "    train_index, val_index = next(sss2.split(dev_images, dev_labels))\n",
    "\n",
    "    # Creating train, validation, and test dictionaries\n",
    "    train_images = images[train_index]\n",
    "    train_labels = labels[train_index]\n",
    "    val_images = images[val_index]\n",
    "    val_labels = labels[val_index]\n",
    "\n",
    "    train_set = {\"X\": train_images, \"Y\": train_labels}\n",
    "    val_set = {\"X\": val_images, \"Y\": val_labels}\n",
    "    test_set = {\"X\": test_images, \"Y\": test_labels}\n",
    "\n",
    "    return {\"Train\": train_set, \"Validation\": val_set, \"test\": test_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "images_path = normalized_path + \"/**/*.png\"\n",
    "images, labels_int, classes = list_data_and_prepare_labels(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "all_dataset = split_data(images, labels_int, VAL_SPLIT, TEST_SPLIT)\n",
    "train_set = all_dataset[\"Train\"]\n",
    "val_set = all_dataset[\"Validation\"]\n",
    "test_set = all_dataset[\"Validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my_transforms.py\n",
    "\n",
    "torch_vision_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4120, 0.3768, 0.3407],\n",
    "        std=[0.2944, 0.2759, 0.2598],\n",
    "    )\n",
    "])\n",
    "\n",
    "torch_vision_transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4120, 0.3768, 0.3407],\n",
    "        std=[0.2944, 0.2759, 0.2598],\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóëÔ∏è Garbage Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from garbage_model.py\n",
    "\n",
    "class GarbageModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape: tuple, num_classes: int, learning_rate: float = 2e-4, transfer: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # transfer learning if pretrained=True\n",
    "        self.feature_extractor = models.resnet18(pretrained=transfer)\n",
    "\n",
    "        if transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        n_features = self._get_conv_output(self.input_shape)\n",
    "        self.classifier = nn.Linear(n_features, num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self.feature_extractor(tmp_input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from base_dataset.py\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data_dic: dict, transform: transforms.transforms.Compose = None):\n",
    "        self.file_paths = data_dic[\"X\"]\n",
    "        self.labels = data_dic[\"Y\"]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        file_path = self.file_paths[idx]\n",
    "        \n",
    "        # Read an image with PIL and convert it to RGB\n",
    "        image = Image.open(file_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert label to a Long tensor\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 1 3 1 2 1 2 0 2 3 3 2 2 0 1 1 1 0 1 0 2 2 2 1 1 2 3 0 2 1 2 2 3 0 2\n",
      " 3 3 3 1 0 1 0 2 2 1 0 1 1 1 0 3 3 0 2 1 0 2 2 2 1 2 0 1 2 2 0 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset\n",
    "train_dataset = BaseDataset(train_set, transform=torch_vision_transform)\n",
    "print(train_dataset.labels)\n",
    "val_dataset = BaseDataset(val_set, transform=torch_vision_transform)\n",
    "test_dataset = BaseDataset(test_set,transform= torch_vision_transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_stats(data_loader):\n",
    "    \"\"\"\n",
    "    Get mean and std stats.\n",
    "    \"\"\"\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in data_loader:\n",
    "        data = data[0]  # Get the images to compute the stgatistics\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.3629, 0.3255, 0.3942]), tensor([0.9863, 1.0403, 1.1084]))\n"
     ]
    }
   ],
   "source": [
    "print(get_dataset_stats(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator = iter(train_loader)\n",
    "# train_batch = next(train_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèÉ‚Äç‚ôÇÔ∏è Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/redge/anaconda3/envs/enel645/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/enel645/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GarbageModel(\n",
       "  (feature_extractor): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1000, out_features=4, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "net_18 = GarbageModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES, transfer=True)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net_18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mredgesantillan\u001b[0m (\u001b[33menel-645\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/redge/Library/CloudStorage/OneDrive-UniversityofCalgary/School/MEng/Winter2024/enel645/ENSF-611-ENEL-645/ENEL 645/A2/notebooks/wandb/run-20240304_231921-auk39w51</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/enel-645/enel-645-garbage-classifier/runs/auk39w51' target=\"_blank\">test-run</a></strong> to <a href='https://wandb.ai/enel-645/enel-645-garbage-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/enel-645/enel-645-garbage-classifier' target=\"_blank\">https://wandb.ai/enel-645/enel-645-garbage-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/enel-645/enel-645-garbage-classifier/runs/auk39w51' target=\"_blank\">https://wandb.ai/enel-645/enel-645-garbage-classifier/runs/auk39w51</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from train_utils.py\n",
    "\n",
    "# Custom class\n",
    "from src.base_dataset import BaseDataset\n",
    "from src.garbage_model import GarbageModel\n",
    "\n",
    "wandb.init(\n",
    "    project=\"enel-645-garbage-classifier\",\n",
    "    name=\"test-run\",\n",
    "    config={\"learning_rate\": 0.02, \"architecture\": \"resnet_18\", \"dataset\": \"CVPR_2024_dataset\", \"epochs\": 12}\n",
    ")\n",
    "\n",
    "def train_validate(model: GarbageModel, train_loader: BaseDataset, val_loader: BaseDataset, epochs: int, learning_rate: float, best_model_path: str, device: torch.device, verbose: bool = True) -> None:\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    best_loss = 1e+20\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch + 1}, Train loss: {train_loss / len(train_loader):.3f}', end=' ')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "            if verbose:\n",
    "                print(f'Val loss: {val_loss / len(val_loader):.3f}')\n",
    "\n",
    "        # Log training and validation loss to wandb\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            if verbose:\n",
    "                print(\"Saving model\")\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            best_loss = val_loss\n",
    "\n",
    "    if verbose:\n",
    "        print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.510 Val loss: 1.592\n",
      "Saving model\n",
      "Epoch 2, Train loss: 1.102 Val loss: 1.299\n",
      "Saving model\n",
      "Epoch 3, Train loss: 0.937 Val loss: 1.554\n",
      "Epoch 4, Train loss: 0.894 Val loss: 1.210\n",
      "Saving model\n",
      "Epoch 5, Train loss: 0.788 Val loss: 1.222\n",
      "Epoch 6, Train loss: 0.794 Val loss: 1.062\n",
      "Saving model\n",
      "Epoch 7, Train loss: 0.695 Val loss: 1.047\n",
      "Saving model\n",
      "Epoch 8, Train loss: 0.625 Val loss: 1.059\n",
      "Epoch 9, Train loss: 0.546 Val loss: 1.212\n",
      "Epoch 10, Train loss: 0.722 Val loss: 1.117\n",
      "Epoch 11, Train loss: 0.580 Val loss: 0.899\n",
      "Saving model\n",
      "Epoch 12, Train loss: 0.533 Val loss: 1.044\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_validate(net_18, train_loader, val_loader, EPOCHS, LEARNING_RATE, best_model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/redge/anaconda3/envs/enel645/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/redge/anaconda3/envs/enel645/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the best model to be used in the test set\n",
    "net = GarbageModel((3,224,224), 4, False)\n",
    "net.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 45.833333333333336 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the network on the test images: {100 * correct / total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calgary_di",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
